```
layout:     post
title:      人工智能学习路径
subtitle:   人工智能学习分解
date:       2025-6-30
author:     BY hangyu
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 人工智能
    - 路线图
    
```

# 前言

人工智能技术大致划分为人工智能开发入门，机器学习核心技术，深度学习核心技术，NLP自然语言处理技术，CV计算机视觉技术这五个方面

## 人工智能开发入门

![人工智能开发入门](https://github.com/DarkFriday0288/picx-images-hosting/raw/master/image.45hxtyvhki.webp)

### Python 编程

Python 是人工智能开发的主流语言。

- **基本语法**：包括变量定义、数据类型（数字、字符串、列表等）、语句结构（if - else、for、while）等，是编写 Python 程序的基础。
- **数据结构**：如列表（有序可变集合）、元组（有序不可变集合）、字典（键值对集合），用于高效存储和管理数据。
- **函数**：可将重复使用的代码块封装，提高代码复用性，有内置函数和自定义函数。
- **面向对象**：涉及类和对象的概念，通过封装、继承、多态实现代码的模块化和可扩展性。
- **多任务**：包含多线程（同一时间处理多个任务片段）和多进程（同时运行多个独立程序），提升程序执行效率。
- **模块与包**：模块是包含 Python 代码的文件，包是模块的集合，方便代码组织和管理。
- **闭包、装饰器、迭代器**：闭包可保留函数内部状态；装饰器用于修改函数或类的行为；迭代器可用于遍历集合元素。

### Numpy 矩阵运算

Numpy 用于数值计算，尤其擅长矩阵运算。

- **Ndarray**：Numpy 的核心数据结构，即 n 维数组对象，支持高效的数值存储和运算。
- **Scalars**：标量，即单个数值，是 Ndarray 元素的基本类型。
- **Broadcasting**：广播机制，允许不同形状的数组间进行运算。
- **矩阵运算**：如矩阵乘法、加法等，是深度学习中张量运算的基础。
- **矩阵转置**：交换矩阵的行和列。
- **矩阵求逆**：用于求解线性方程组等问题。

### Scipy 数值运算库

Scipy 建立在 Numpy 之上，提供更多数值计算功能。

- **基本使用**：涵盖安装、导入及基础函数调用。
- **常量**：如圆周率 π 等科学计算常用常量。
- **稀疏矩阵**：用于存储和处理元素大部分为零的矩阵，节省内存和计算资源。
- **图结构**：处理图相关算法，如最短路径等。
- **空间**：包含空间数据结构和算法，如 KD 树等。
- **插值**：根据已知数据点估算未知点的值。

### Pandas 数据科学库

Pandas 用于数据处理和分析。

- **自带数据结构**：Series（一维标记数组）和 DataFrame（二维表格型数据结构）。
- **数据读取与写入**：可读取多种格式数据（如 CSV、Excel 等），并将处理后的数据保存。
- **数据清洗**：处理缺失值、重复值、异常值等，保证数据质量。
- **数据计算**：执行统计计算（均值、方差等）、分组计算等。
- **数据合并**：将多个数据集按特定规则合并，如横向拼接和纵向拼接。
- **数据排序**：按指定列或索引对数据进行升序或降序排列。

### Matplotlib

Matplotlib 是绘图库。

- **基础图表**：能绘制折线图、柱状图、散点图等基本图形。
- **Annotation**：用于给图表添加注释，使图表信息更丰富。
- **Figure**：代表整个图表窗口，可设置图表大小、分辨率等属性。
- **子图**：在一个图表中绘制多个子图，便于对比分析。
- **Legend**：为图表添加图例，标识不同数据系列。

### Seaborn

Seaborn 基于 Matplotlib，更专注于统计数据可视化。

- **数据关系图**：如绘制散点图展示变量间关系。
- **数据分布图**：如直方图、核密度估计图展示数据分布。
- **类别图**：展示不同类别数据的差异，如箱线图。
- **回归图**：绘制线性回归模型拟合图等。
- **矩阵图**：如热力图展示数据矩阵的相关性。
- **多变量关系**：分析和展示多个变量间复杂关系。

### Pyecharts

Pyecharts 用于创建交互式可视化图表，适用于 Web 应用。

- **基本使用**：包括安装、初始化图表等基础操作。
- **图表 API**：提供各类图表（如折线图、柱状图等）的绘制接口。
- **组合图表**：将多种图表类型组合，呈现更丰富信息。
- **其他资源**：如主题设置、颜色配置等。
- **图表类型**：涵盖多种图表，满足不同可视化需求。
- **Web 框架整合**：方便与 Flask、Django 等 Web 框架集成。



## 机器学习核心技术

![机器学习核心技术](https://github.com/DarkFriday0288/picx-images-hosting/raw/master/image.ice6fvv89.webp)

### Scikit Learn

Scikit Learn 是 Python 中常用的机器学习库。

- **聚类算法 API**：用于将数据点划分成不同组，无监督学习方式，可发现数据内在结构。
- **数据预处理**：包括对数据的清洗、标准化、编码等操作，提升数据质量，让算法更好适配。
- **分类算法 API**：对数据进行类别划分，如判断邮件是垃圾邮件或正常邮件。
- **回归算法 API**：用于预测连续值，如根据房屋特征预测房价。

### 分类算法

分类算法是机器学习中的监督学习技术 ，作用是将数据或对象分组到不同的预定义类别或标签中。

- **决策树**：基于树结构进行决策，通过对特征的不断划分构建树模型。
- **KNN（K - 近邻算法）**：根据样本的 k 个最近邻来判断样本类别。
- **Adaboost**：集成学习算法，通过组合多个弱分类器形成强分类器。
- **随机森林**：由多棵决策树构成的集成学习模型，能降低过拟合风险。
- **逻辑回归**：虽名字有 “回归”，实则用于分类，基于概率预测类别。
- **朴素贝叶斯**：基于贝叶斯定理，假设特征间相互独立进行分类。
- **GBDT（梯度提升决策树）**：通过迭代拟合梯度残差构建决策树。
- **Xgboost**：高效的梯度提升框架，在速度和性能上有优势。
- **LightGBM**：轻量级梯度提升框架，采用直方图算法等优化，训练速度快。

### 回归算法

回归算法是机器学习中的一种监督学习方法 ，主要用于预测数值型目标变量，通过建立特征与目标变量之间的关系模型，对未知数据做出预测。

- **线性回归**：建立自变量和因变量的线性关系模型。
- **Lasso 回归**：在线性回归基础上加入 L1 正则化，可用于特征选择。
- **决策树回归**：用决策树预测连续值。
- **随机森林回归**：多棵决策树回归的集成，提高预测稳定性。
- **Xgboost 回归**：用于预测连续目标值，利用 Xgboost 框架优势。

### 聚类算法

聚类算法是一种无监督学习方法，主要作用体现在以下几个方面：

### 1.发现数据内在结构和模式

聚类算法能把没有类别标签的数据，按照数据点之间的相似性划分成不同组或簇。比如分析大量用户的网络行为数据，像浏览网页时长、访问页面类型、点击广告频率等，通过聚类算法就能发现用户行为的模式，找到具有相似行为模式的用户群体，进而了解数据中隐藏的结构 。

### 2.数据分组与分类

- **市场细分**：在商业领域，企业可依据客户的购买频率、消费金额、购买偏好等信息，运用聚类算法将客户分成不同群体，像高端消费群体、价格敏感型群体、冲动消费群体等。这样企业就能针对不同群体的特点制定营销策略，如为高端消费群体提供专属服务和限量商品，给价格敏感型群体推送优惠折扣信息。
- **图像分割**：在计算机视觉中，将图像中具有相似特征（颜色、纹理、形状等）的像素点聚成一类，把图像分割成不同区域。比如对一张风景图，可分割出天空、草地、树木、建筑物等不同部分，有助于后续的图像理解、目标识别等任务。
- **生物分类**：分析生物基因序列或蛋白质结构数据，把具有相似特征的生物样本聚类，发现新的生物类别或物种之间的关系，辅助生物学家进行分类研究和进化分析。

### 3.异常检测

聚类时，处于大多数簇之外的孤立数据点往往可视为异常点。在金融领域，通过对用户交易数据（交易金额、时间、地点等）聚类，能找出与正常交易模式差异大的异常交易，可能是欺诈行为，及时预警防范风险；在工业生产中，对设备运行参数聚类，能发现偏离正常运行模式的参数组合，提示设备可能出现故障。

### 4.辅助决策和探索性分析

- **社交网络分析**：分析社交网络中用户之间的互动关系（点赞、评论、私信等频率），聚类出关系紧密的社交圈子，了解社交网络的结构和群体特征，为精准营销、推荐系统等提供依据，比如向同一社交圈子的用户推荐相似产品或内容。

- **科学研究**：在物理、化学等科研领域，对实验数据聚类，发现数据中的规律和趋势，帮助科学家提出新的假设和研究方向 。比如分析不同材料的物理性质数据，聚类出具有相似性质的材料类别，探索新材料的应用场景。

  

## 深度学习核心技术

![深度学习核心技术](https://github.com/DarkFriday0288/picx-images-hosting/raw/master/image.491jrosqiz.webp)

### 人工神经网络

- **损失函数**：用于衡量模型预测值与真实值之间的差异，常见的有均方误差（MSE，用于回归问题）、交叉熵损失（用于分类问题 ）等。通过最小化损失函数来优化模型参数。
- **激活函数**：赋予神经网络非线性特性，使它能学习和模拟复杂的非线性关系。如 Sigmoid、ReLU、tanh 等。例如 ReLU（Rectified Linear Unit），公式为*f*(*x*)=*ma**x*(0,*x*) ，计算简单且能缓解梯度消失问题。
- **Back Propagation（反向传播）**：是训练神经网络的关键算法。通过计算损失函数对各层参数的梯度，从输出层反向传播回输入层，进而更新网络参数，以降低损失。
- **优化方法及正则化**：优化方法如随机梯度下降（SGD）及其变种（Momentum、Adagrad、Adam 等 ），用于更新模型参数。正则化是防止模型过拟合的技术，如 L1 和 L2 正则化，通过在损失函数中添加正则化项，约束模型参数规模。

### BP 神经网络

- **网络基本结构**：一般包含输入层、隐藏层和输出层。层与层之间神经元通过权重连接，信息从输入层经隐藏层流向输出层。
- **正向计算**：输入数据经各层加权求和并通过激活函数，逐层向前计算，得到最终输出。
- **链式法则**：反向传播中计算梯度的重要数学工具，用于计算损失函数对各层参数的偏导数。
- **权重更新**：根据反向传播计算出的梯度，结合优化算法（如 SGD ）来更新神经元之间的连接权重。
- **Sigmoid 函数**：曾常用的激活函数，将输入值映射到 (0, 1) 区间，公式为*f*(*x*)=1+*e*−*x*1 ，但存在梯度消失问题。
- **梯度消失 / 爆炸**：在深度神经网络中，反向传播时梯度可能逐渐趋近于 0（梯度消失）或变得极大（梯度爆炸），导致网络难以训练。
- **Batch Normalization**：对神经网络的每一个小批量数据进行归一化处理，使数据分布更稳定，加速模型收敛，缓解梯度消失问题。

### CNN 卷积神经网络

- **局部感受野**：卷积层中神经元只与输入数据的局部区域相连，模拟生物视觉的局部感知机制，减少连接参数数量。
- **权值共享**：同一卷积核在处理输入数据不同位置时，权重保持不变，大幅减少模型参数数量，提高计算效率。
- **DropOut**：防止过拟合的技术，训练过程中随机将部分神经元的输出置为 0，避免神经元间过度依赖。
- **卷积层**：通过卷积核与输入数据进行卷积运算，提取数据特征，如在图像中提取边缘、纹理等特征。
- **池化层**：常见有最大池化和平均池化，对卷积层输出进行下采样，减少数据维度，降低计算量，同时保留主要特征。
- **全连接层**：将前面层提取的特征进行整合，输出最终分类或回归结果。

### RNN 循环神经网络

- **梯度裁剪**：在 RNN 训练中，为防止梯度爆炸，设置一个阈值，当梯度超过该阈值时进行裁剪。
- **双向长短期记忆网络（BiLSTM）**：结合了正向和反向的 LSTM，能同时利用过去和未来的信息，在处理序列数据（如自然语言 ）时效果较好。
- **长短期记忆网络（LSTM）**：专门设计用于解决 RNN 中梯度消失问题，通过门控机制（输入门、遗忘门、输出门）控制信息的流入、流出和记忆，有效捕捉长序列中的长期依赖关系。
- **门控神经网络（GRU）**：LSTM 的变体，结构相对简单，只有重置门和更新门，能有效处理序列数据中的长期依赖，计算效率更高。

## NLP自然语言处理技术

![NLP自然语言处理技术](https://github.com/DarkFriday0288/picx-images-hosting/raw/master/image.83aban8ln8.webp)

### **什么是 NLP？**

NLP（Natural Language Processing）就是让计算机理解、处理和生成人类语言的技术。

比如

- 你对 Siri 说 “帮我订明天的机票”，它能听懂并执行 —— 这是 NLP 在 “理解” 语言；
- 翻译软件把 “我爱你” 翻译成英语 “I love you”—— 这是 NLP 在 “处理” 语言；
- AI 写小说、生成文案 —— 这是 NLP 在 “生成” 语言。
  核心目标：让机器像人一样 “懂” 语言的意思，甚至 “说” 出流畅的话。

### **NLP 的发展历程：从 “笨笨的规则” 到 “聪明的 AI”**

1. **规则时代（1950-1990）**
   - 靠人工编写语法规则（如 “主语 + 谓语 + 宾语”），但只能处理简单句子，遇到复杂语境就 “傻眼”。
   - 例子：早期机器翻译只能按词典逐词翻译，比如 “我吃火锅” 翻译成 “I eat fire pot”，生硬又搞笑。
2. **统计时代（1990-2010）**
   - 用数学模型分析海量语料，比如通过统计 “我爱” 后面接 “学习” 的概率更高，来预测句子走向。
   - 代表技术：隐马尔可夫模型（HMM）、条件随机场（CRF），让机器翻译、语音识别准确率提升。
3. **深度学习时代（2010 至今）**
   - 用神经网络模拟人脑，让机器自己 “学” 语言规律。
   - 里程碑：Transformer 模型（2017 年提出），让 NLP 能力爆发式增长，比如 GPT 系列（写文章、对话）、BERT（阅读理解）等。

### Pytorch 编程

- **定义损失函数**：用于衡量模型预测结果与真实结果的差异程度，常见的有交叉熵损失函数（适用于分类任务）、均方误差损失函数（常用于回归任务 ）等，帮助模型学习如何调整参数以减少预测误差。
- **自动微分功能**：PyTorch 的核心特性之一，能自动计算张量运算的梯度，在训练模型时，可根据损失函数自动计算参数的梯度，方便进行反向传播和参数更新。
- **定义优化器**：优化器负责根据计算出的梯度来更新模型参数，常见的有随机梯度下降（SGD）、Adam、Adagrad 等，不同优化器有不同的更新策略和适用场景。
- **定义模型结构**：基于 PyTorch 的模块（nn.Module）来搭建神经网络模型，如定义各层的类型（全连接层、卷积层等 ）、神经元数量、连接方式等，构建出适合 NLP 任务的模型架构。

### 传统序列模型

- **隐马尔可夫模型（HMM）**：是一种基于概率的有向图模型，用于处理时序数据，由隐藏状态序列和可观测状态序列组成，常用于词性标注、语音识别等任务，通过状态转移概率和观测概率来推断隐藏状态。
- **条件随机场（CRF）**：是一种无向图模型，考虑了整个序列的标注情况，在命名实体识别、分词等任务中表现良好，通过定义特征函数和权重来计算标注序列的概率。
- **原理与实践**：深入理解 HMM 和 CRF 的数学原理，包括概率计算、参数估计等，并在实际 NLP 项目中应用，如使用工具包（如 Python 的 NLTK、CRFSuite 等）进行模型训练和预测。
- **CRF 与 HMM 区别**：HMM 是生成式模型，对观测序列和隐藏状态序列联合建模；CRF 是判别式模型，直接对条件概率建模。CRF 能更好地利用上下文信息，在一些任务上性能优于 HMM。

### Transformer 原理

- **编码器**：Transformer 的重要组成部分，由多个相同的层堆叠而成，每层包含多头自注意力机制和前馈神经网络，主要功能是对输入序列进行编码，提取特征。
- **解码器**：同样由多层组成，在编码器基础上增加了掩码多头自注意力机制和交叉注意力机制，用于生成目标序列，如在机器翻译中生成翻译后的句子。
- **注意力机制**：Transformer 的核心，允许模型在处理序列时关注不同位置的信息，增强模型对重要信息的捕捉能力，常见的有自注意力（Self - Attention）和多头注意力（Multi - Head Attention）。
- **语言模型**：基于 Transformer 构建的语言模型，如 BERT、GPT 等，通过预训练学习大量文本数据中的语言模式和语义信息，可应用于多种 NLP 任务。
- **模型超参数**：包括层数、隐藏层维度、注意力头数、学习率等，这些参数影响模型的性能和训练效果，需要通过实验进行调优。
- **模型验证**：使用验证集对训练好的 Transformer 模型进行评估，常用指标有准确率、困惑度等，根据评估结果调整模型或超参数，以提高模型的泛化能力。

### 文本预处理

- **文本处理基本方法**：包括文本清洗（去除噪声、特殊字符等 ）、分词（将文本拆分成单词或子词 ）、词性标注等，是 NLP 任务的基础步骤，提高文本数据质量。
- **文本张量表示方法**：将文本数据转换为计算机可处理的张量形式，如独热编码（One - Hot Encoding）、词嵌入（Word Embedding ）等，不同表示方法对模型性能有影响。
- **文本语料数据分析**：对收集到的文本语料库进行统计分析，了解文本的长度分布、词汇频率、主题分布等，为后续的模型选择和训练提供依据。
- **数据增强方法**：通过同义词替换、随机插入 / 删除单词、回译等技术扩充文本数据量，增加数据多样性，提高模型的泛化能力。
- **命名实体识别**：识别文本中具有特定意义的实体，如人名、地名、组织机构名等，是信息抽取、知识图谱构建等任务的基础。
- **Word Embedding 词嵌入**：将单词映射到低维向量空间，使语义相近的单词在向量空间中距离较近，常见的有 Word2Vec、GloVe 等，能有效捕捉单词的语义信息。

### RNN 及变体

- **传统 RNN**：循环神经网络，具有记忆功能，能处理序列数据，通过隐藏状态传递信息，但存在梯度消失或梯度爆炸问题，在处理长序列时效果不佳。
- **LSTM（长短期记忆网络）**：专门设计用于解决 RNN 梯度消失问题，通过门控机制（输入门、遗忘门、输出门）控制信息的流入、流出和记忆，能有效捕捉长序列中的长期依赖关系。
- **Bi - LSTM（双向长短期记忆网络）**：结合了正向和反向的 LSTM，能同时利用过去和未来的信息，在处理序列数据（如自然语言 ）时效果较好，常用于情感分析、命名实体识别等任务。
- **GRU（门控循环单元）**：LSTM 的变体，结构相对简单，只有重置门和更新门，能有效处理序列数据中的长期依赖，计算效率更高。
- **Bi - GRU（双向门控循环单元）**：将双向结构引入 GRU，兼具双向网络和 GRU 的优势，在一些 NLP 任务中表现出色。
- **Seq2Seq**：序列到序列模型，通常由编码器和解码器组成，可用于机器翻译、文本摘要等任务，将一个序列转换为另一个序列。

### 迁移学习

- **FastText**：是一种快速文本分类和词向量训练工具，能高效处理大规模文本数据，在文本分类任务中表现良好，其模型结构简单，训练速度快。
- **预训练模型**：在大规模语料上预先训练好的模型，如 BERT、GPT 等，这些模型学习到了丰富的语言知识和语义表示，可迁移到其他 NLP 任务中，减少训练时间和数据需求。
- **Google BERT**：基于 Transformer 的双向编码器表征，通过掩码语言模型和下一句预测任务进行预训练，在多种 NLP 任务（如问答系统、文本分类等 ）上取得了优异成绩。
- **GPT**：生成式预训练 Transformer，通过自监督学习方式在大量文本上预训练，从 GPT 到 GPT - 2 不断改进，具有强大的文本生成能力。
- **GPT - 2**：GPT 的升级版，增加了模型规模和训练数据量，在文本生成、对话系统等方面表现更为出色，展现了强大的语言理解和生成能力。
- **权重微调**：将预训练模型应用到具体任务时，固定部分层的参数，对其他层的参数在目标任务数据上进行微调，使模型适应新任务，提高在特定任务上的性能。

## CV计算机视觉技术

![CV计算机视觉技术](https://github.com/DarkFriday0288/picx-images-hosting/raw/master/image.mchv4mwn.webp)

### OpenCV 图像处理

- **读写图像**：OpenCV 提供函数读取（如`cv2.imread()` ）和保存（如`cv2.imwrite()` ）多种格式图像，是图像处理基础操作。
- **灰度变换**：将彩色图像转为灰度图像，减少数据量，突出图像亮度特征，常用方法有加权平均法等。
- **几何变换**：包括平移、旋转、缩放、翻转等操作，改变图像形状和位置，用于图像校正、配准等。
- **形态学**：基于形状的图像处理技术，常用操作有腐蚀、膨胀、开运算、闭运算等，用于去除噪声、分割物体等。
- **纹理分割**：依据图像纹理特征将其分割为不同区域，用于图像分析和理解。
- **视频操作**：处理视频流，包括读取视频帧（`cv2.VideoCapture` ）、写入视频（`cv2.VideoWriter` ）等，可用于视频编辑、目标跟踪等。
- **边缘检测技术**：检测图像中物体边缘，常用算法有 Canny、Sobel 等，是目标识别和分割基础。
- **特征检测和描述**：提取图像特征点（如 SIFT、SURF、ORB ），并描述其特征，用于图像匹配、目标识别等。

### Tensorflow 编程

- **张量**：TensorFlow 核心数据结构，代表多维数组，是计算基础，可进行各种数学运算。
- **变量**：用于存储可训练参数，在模型训练中更新，如神经网络权重和偏置。
- **高阶 API**：如`tf.keras` ，提供简洁易用接口构建、训练和评估模型，降低开发难度。
- **tf.data**：用于高效加载、预处理和批量处理数据，支持从多种数据源读取数据。
- **tf.keras**：高级神经网络 API，内置多种层和模型，方便构建深度学习模型，支持快速实验和迭代。

### 目标分类

- **卷积计算方法**：卷积神经网络（CNN）核心操作，通过卷积核在图像上滑动计算提取特征，不同卷积核可提取不同特征。
- **多通道卷积**：处理彩色图像等多通道数据，每个通道单独卷积后融合，增强特征提取能力。
- **AlexNet**：早期成功的深度 CNN 模型，在 2012 年 ImageNet 竞赛夺冠，推动深度学习在 CV 领域发展。
- **VGG**：结构简单、深度较深的 CNN 模型，以其规整网络结构和良好性能闻名，广泛用于图像分类。
- **ResNet 残差网络**：引入残差连接解决深度网络梯度消失等问题，可训练更深网络，提升分类准确率。
- **ImageNet 分类**：在大规模图像数据集 ImageNet 上进行分类任务，是评估图像分类模型性能重要标准。

### 目标检测

- **RCNN**：基于区域的卷积神经网络，开启深度学习目标检测先河，通过提取候选区域并分类检测目标。
- **FPN（特征金字塔网络）**：融合不同尺度特征图信息，提升对不同大小目标检测能力。
- **SSD（单次多框检测器）**：单阶段目标检测算法，速度快，可实时检测目标，适用于资源受限场景。
- **ROI Pooling（感兴趣区域池化）**：从候选区域提取固定大小特征图，供后续分类和定位，是目标检测关键操作。
- **Faster RCNN**：在 RCNN 基础上改进，引入区域建议网络（RPN），提高检测速度和准确率。
- **非极大抑制 NMS**：去除重叠候选框，保留得分最高框，解决目标检测中重复检测问题。

### 目标分割

- **全卷积**：将传统 CNN 全连接层转换为卷积层，输出分割结果，可处理任意大小图像。
- **ROI Align**：改进 ROI Pooling，更精准提取特征，提升实例分割精度。
- **DeepLab**：语义分割模型，利用空洞卷积扩大感受野，结合 CRF 优化分割结果。
- **Mask RCNN**：在 Faster RCNN 基础上增加分割分支，同时实现目标检测和实例分割。
- **金字塔池化模块**：融合不同尺度特征，获取全局和局部信息，提升分割性能。
- **语义分割评价标准**：如像素准确率、平均交并比等，衡量语义分割模型分割结果与真实标注一致性。

